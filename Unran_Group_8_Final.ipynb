{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group 8 Final Project\n",
    "\n",
    "## Group Members: Gabriel Colón, Philip Felizarta, and Parker Christenson \n",
    "\n",
    "### Data set Selected: MNIST Dataset \n",
    "\n",
    "`Description of the Dataset`: The MNIST database of handwritten digits, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image. It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA) - Parker Christenson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the model from tensorflow\n",
    "\n",
    "(X_train,y_train),(X_test,y_test)=tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the x_train and y_train data shapes \n",
    "print(\"X_train shape:\",X_train.shape,\"X_test shape:\",X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can now see that we have 60,000 images in our training set and 10,000 images in our test set.\n",
    "#### Which is a good split for our testing and training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the pixel values\n",
    "x_train = x_train / 255.0\n",
    "\n",
    "# list to store the avg's\n",
    "average_digits = []\n",
    "\n",
    "# calc the avg shape for each digit \n",
    "for digit in range(10):\n",
    "\n",
    "    # Extract all images for this digit\n",
    "    images = x_train[y_train == digit]\n",
    "    \n",
    "    # Calculate the mean image\n",
    "    mean_image = np.mean(images, axis=0)\n",
    "    average_digits.append(mean_image)\n",
    "\n",
    "# plotting the avg image shapes\n",
    "fig, axes = plt.subplots(1, 10, figsize=(20, 2))\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(average_digits[i], cmap='gray')\n",
    "    ax.set_title(str(i))\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This output is what every Numbers average looks like in the MNIST data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting the number of ocurrences for each digit\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "\n",
    "# plotting \n",
    "plt.bar(unique, counts)\n",
    "plt.xlabel('Digits')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Distribution of Digits in MNIST Dataset')\n",
    "plt.xticks(unique)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "\n",
    "# printing the counts of each digit \n",
    "for digit, count in zip(unique, counts):\n",
    "    print(f\"Digit {digit}: {count} occurrences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is the distribution of the MNIST data set.\n",
    "\n",
    "#### Digit 0: 5923 occurrences\n",
    "#### Digit 1: 6742 occurrences\n",
    "#### Digit 2: 5958 occurrences\n",
    "#### Digit 3: 6131 occurrences\n",
    "#### Digit 4: 5842 occurrences\n",
    "#### Digit 5: 5421 occurrences\n",
    "#### Digit 6: 5918 occurrences\n",
    "#### Digit 7: 6265 occurrences\n",
    "#### Digit 8: 5851 occurrences\n",
    "#### Digit 9: 5949 occurrences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-map of the MNIST Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.umap_ as umap\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), _ = mnist.load_data()\n",
    "x_train_flat = x_train.reshape(-1, 28*28)  # Flatten the images\n",
    "\n",
    "reducer = umap.UMAP(random_state=42)\n",
    "embedding = reducer.fit_transform(x_train_flat[:10000]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], c=y_train[:10000], cmap='Spectral', s=5)\n",
    "plt.colorbar(boundaries=np.arange(11)-0.5).set_ticks(np.arange(10))\n",
    "plt.title('UMAP projection of the MNIST dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is a U-map of the MNIST data set. It is a 2D representation of the data set. It is a good way to visualize the data set, and be able to understand the way the data set looks. With that being said, the U-map function is a really good way to get a visual representation of the data set, and see how the data set is distributed, and some of the patterns and potential problems within the data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a 3D representation of the MNIST data set using a U-Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), _ = mnist.load_data()\n",
    "x_train_flat = x_train.reshape(-1, 28*28)\n",
    "\n",
    "# Reduce dimensions to 3D using UMAP\n",
    "reducer = umap.UMAP(n_components=3, random_state=42)\n",
    "embedding_3d = reducer.fit_transform(x_train_flat[:10000])\n",
    "\n",
    "# Create a Plotly 3D scatter plot\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=embedding_3d[:, 0],\n",
    "    y=embedding_3d[:, 1],\n",
    "    z=embedding_3d[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=5,\n",
    "        color=y_train[:10000],  # set color to the labels\n",
    "        colorscale='Viridis',   # choose a colorscale\n",
    "        opacity=0.8\n",
    "    )\n",
    ")])\n",
    "\n",
    "# Update layout for a better view\n",
    "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SK-Learn Model - Gabriel Colón"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model - Philip Felizarta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tensorflow.keras as keras\n",
    "import model_api as api\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_model = api.NN_classifier(32, 2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model = api.CNN_classifier(16, 4, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
